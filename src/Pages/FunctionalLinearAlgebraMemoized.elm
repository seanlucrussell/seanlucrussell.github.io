module Pages.FunctionalLinearAlgebraMemoized exposing (..)

import Components exposing (blogHeading)
import Date exposing (fromPosix)
import Html.Styled exposing (..)
import Html.Styled.Attributes exposing (..)
import Json.Encode as Encode
import Sitewide.Types exposing (Article, Page)
import Time exposing (Month(..), millisToPosix, utc)


page : Page
page =
    { view =
        \_ ->
            Html.Styled.article []
                [ blogHeading (text "Functional Linear Algebra, Memoized") article.publicationDate
                , p [] [ text "This is a second appendix to ", a [ href "/FNLINALG" ] [ text "Functional Linear Algebra" ], text ". It’s a continuation of the first appendix, really, ", a [ href "/FNLINALGTYPED" ] [ text "Functional Linear Algebra, With Types" ], text ". There we extended the original Python implementation in Haskell so all our matrix and vector operations are very nicely typed. But in the process we lost a lot of performance. This brief note discusses memoizing the Haskell impelmentation." ]
                , p [] [ text "The idea is pretty simple, actually. The reason performance suffered has to do with our representation of vectors as functions. When we describe a vector in terms of a big chain of operations that involve contractions, we unfortunately do not typically share those contraction results across indices. If we have a 3d vector defined as a product ", node "katex-expression" [ attribute "katex-options" (Encode.encode 0 (Encode.object [ ( "displayMode", Encode.bool False ), ( "throwOnError", Encode.bool False ) ])), attribute "expression" "M\\vec v"] [], text ", then to find ", node "katex-expression" [ attribute "katex-options" (Encode.encode 0 (Encode.object [ ( "displayMode", Encode.bool False ), ( "throwOnError", Encode.bool False ) ])), attribute "expression" "\\vec v_i"] [], text " and ", node "katex-expression" [ attribute "katex-options" (Encode.encode 0 (Encode.object [ ( "displayMode", Encode.bool False ), ( "throwOnError", Encode.bool False ) ])), attribute "expression" "\\vec v_j"] [], text " we are running a the same contraction over indices two different times. This is obviously redundant. This results in our power iteration running in ", node "katex-expression" [ attribute "katex-options" (Encode.encode 0 (Encode.object [ ( "displayMode", Encode.bool False ), ( "throwOnError", Encode.bool False ) ])), attribute "expression" "O(d^n)"] [], text " time, where ", node "katex-expression" [ attribute "katex-options" (Encode.encode 0 (Encode.object [ ( "displayMode", Encode.bool False ), ( "throwOnError", Encode.bool False ) ])), attribute "expression" "d"] [], text " is the dimensionality of the matrix and ", node "katex-expression" [ attribute "katex-options" (Encode.encode 0 (Encode.object [ ( "displayMode", Encode.bool False ), ( "throwOnError", Encode.bool False ) ])), attribute "expression" "n"] [], text " is the iteration count." ]
                , p [] [ text "The dumbest way to fix this I know of is to embed a vector or matrix into an array. This effectively forces the computations to be shared. Here is a quick way to do this using some imports from ", code [] [ text "Data.Array" ], text " (full code at the end of this post):" ]
                , pre [] [ code [] [ text "memoizeVector :: forall a. KnownNat a => Vector a -> Vector a\nmemoizeVector v =\n  let\n    bounds =\n        ( fromIntegral (minBound :: Finite a)\n        , fromIntegral (maxBound :: Finite a))\n    arr = listArray bounds (map v finites)\n  in \\i -> arr ! fromIntegral (getFinite i)" ] ]
                , p [] [ text "With this we only change one thing in our existing code. We memoize part of our loop" ]
                , pre [] [ code [] [ text "powerIteration b0 m =\n    ...\n    loop i b' = loop (i-1) (normalize (memoizeVector (mvmul m b')))\n    ..." ] ]
                , p [] [ text "We inject this one call to ", code [] [ text "memoizeVector" ], text ". Now we can increase the number of loop iterations by a whole bunch" ]
                , pre [] [ code [] [ text "powerIteration b0 m =\n    ...\n    b = loop 1000 b0\n    ..." ] ]
                , p [] [ text "(the iterations were maxing out around 7 before) and the code runs almost instantly. We are now pretty firmly in ", node "katex-expression" [ attribute "katex-options" (Encode.encode 0 (Encode.object [ ( "displayMode", Encode.bool False ), ( "throwOnError", Encode.bool False ) ])), attribute "expression" "O(d \\times n)"] [], text " territory for the runtime of this algorithm." ]
                , p [] [ text "Before we end some brief discussion." ]
                , p [] [ text "Full disclosure, I don’t totally love this solution. For a few different reasons. It doesn’t feel very principled. I don’t have a good theory for exactly when it will be necessary to insert these memoization calls, or precisely where to insert them. To figure this instance out I poked at the code for a while and got it to do the right thing but trial-and-error seems like the wrong way to go about optimizing this. It feels like there should be some sort of theory or equational law or standard rewrite or something that makes this fast." ]
                , p [] [ text "I also don’t love throwing away totality within the body of the ", code [] [ text "memoizeVector" ], text " definition. I ", em [] [ text "know" ], text " that the array index lookup will never throw an error, but non-total functions, even those that are well reasoned, give me the ick. Is this a stupid criticism? Probably. But I can’t help but feel that the presence of partiality signals that something fundamental is wrong and that a better approach exists." ]
                , p [] [ text "Nevertheless, memoizing works. And it works really well. The original version of this example took a little over 10 seconds to run 7 power iteration loops and was growing exponentially. The memoized version can run 1,000,000 iterations in under 5 seconds and grows linearly from there. Beautiful or not, memoizing is certainly effective." ]
                , p [] [ text "So there you have it. A fast, type safe, very simple functional implementation of linear algebra in Haskell that represents matrices and vectors as functions. I leave it to you to find whatever meaning you want in this exercise. Perhaps this is just a cool trick. Perhaps it’s a fun excuse to try out some easy, type-level programming. Perhaps this is a deep insight into the fundamental nature of linear algebra. Perhaps it’s a meditation on the benefits and challenges of encoding data with functions. Or perhaps it means something else to you." ]
                , p [] [ text "Whatever the case, I am much obliged that you’ve read through to the end with me. I leave the full source of this memoized implementation in your care. Use it wisely." ]
                , pre [] [ code [] [ text "{-# LANGUAGE ScopedTypeVariables #-}\n{-# LANGUAGE DataKinds #-}\n{-# LANGUAGE TypeApplications #-}\n\nmodule Main where\n\nimport Data.Array\nimport GHC.TypeLits\nimport Data.Finite\nimport Data.Maybe\nimport Data.List\nimport Control.Monad\n\ntype Vector a = Finite a -> Float\ntype Matrix a b = Finite a -> Finite b -> Float\n\ncontract :: forall a. KnownNat a => Vector a -> Float\ncontract f = sum (map f finites)\n\nmmadd :: Matrix a b -> Matrix a b -> Matrix a b\nmmadd m n i j = m i j + n i j\n\nmmmul :: forall a b c. (KnownNat a, KnownNat b, KnownNat c) => Matrix a b -> Matrix b c -> Matrix a c\nmmmul m n i j = contract (\\k -> m i k * n k j)\n\nmvmul :: forall a b. (KnownNat a, KnownNat b) => Matrix a b -> Vector b -> Vector a\nmvmul m v i = contract (\\k -> m i k * v k)\n\nsmmul :: Float -> Matrix a b -> Matrix a b\nsmmul s m i j = s * m i j\n\nsvmul :: Float -> Vector a -> Vector a\nsvmul s v i = s * v i\n\ndot :: forall a. KnownNat a => Vector a -> Vector a -> Float\ndot v w = contract (\\k -> v k * w k)\n\nmagnitude :: forall a. KnownNat a => Vector a -> Float\nmagnitude v = (contract (\\k -> (v k)**2))**0.5\n\nnormalize :: forall a. KnownNat a => Vector a -> Vector a\nnormalize v = svmul (1 / (magnitude v)) v\n\nouter :: Vector a -> Vector b -> Matrix a b\nouter v w i j = v i * w j\n\nvfromlist :: forall n. KnownNat n => [Float] -> Maybe (Vector n)\nvfromlist l = do\n  guard (length l == length (finites @n))\n  pure (\\i -> l !! fromIntegral i)\n\nmfromlist :: forall n m. (KnownNat n, KnownNat m) => [[Float]] -> Maybe (Matrix n m)\nmfromlist l = do\n  guard (length l == length (finites @n))\n  ls <- sequence (fmap vfromlist l)\n  pure (\\i -> ls !! fromIntegral i)\n\nmemoizeVector :: forall a. KnownNat a => Vector a -> Vector a\nmemoizeVector v =\n  let\n    bounds = (fromIntegral (minBound :: Finite a), fromIntegral (maxBound :: Finite a))\n    arr = listArray bounds (map v finites)\n  in \\i -> arr ! fromIntegral (getFinite i)\n\npowerIteration :: forall a. KnownNat a => Vector a -> Matrix a a -> (Float, Vector a)\npowerIteration b0 m =\n  let\n    loop :: Int -> Vector a -> Vector a\n    loop 0 b' = b'\n    loop i b' = loop (i-1) (normalize (memoizeVector (mvmul m b')))\n    b :: Vector a\n    b = loop 1000 b0\n    eigenvalue :: Float\n    eigenvalue = dot b (mvmul m b)\n  in (eigenvalue, b)\n\ndeflate :: forall a. KnownNat a => Matrix a a -> Float -> Vector a -> Matrix a a\ndeflate m s v = mmadd m (smmul (-s / magnitude v) (outer v v))\n\na :: Matrix 3 3\nJust a = mfromlist [[4,1,2],[1,3,0],[2,0,3]]\n\nb0 :: Vector 3\nJust b0 = vfromlist([1,2,3])\n\npow = powerIteration\n\ne1 :: (Float, Vector 3)\ne1 = pow b0 a\na_deflated :: Matrix 3 3\na_deflated = deflate a (fst e1) (snd e1)\ne2 :: (Float, Vector 3)\ne2 = pow b0 a_deflated\n\ndisplay :: (Float, Vector 3) -> String\ndisplay (eval, evec) = \"λ: \" ++ show eval ++ \" \" ++ intercalate \" \" (map (\\i -> show (getFinite i) ++ \": \" ++ show (evec i)) finites)\n\nmain :: IO ()\nmain = do putStrLn (display e1)\n          putStrLn (display e2)" ] ]
                ]
    , update = \_ model -> ( model, Cmd.none )
    }


article : Article
article =
    { title = "Functional Linear Algebra, Memoized"
    , publicationDate = fromPosix utc (millisToPosix 1726855200000)
    , moduleName = "FunctionalLinearAlgebraMemoized"
    , primaryUrl = "/FNLINALGMEMO"
    }
